{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlvXAezGX6-u"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils import np_utils "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar100\n",
        "# let's load data \n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqUhN7WBX8vS",
        "outputId": "64d607a2-11fb-4336-ab07-6b35f12c2870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n",
            "169017344/169001437 [==============================] - 3s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing inputs from 0-255 to 0.0-1.0 \n",
        "X_train = X_train.astype('float32') \n",
        "X_test = X_test.astype('float32') \n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "0mUTDYDQYFxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode outputs \n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "num_classes = y_test.shape[1]\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srvCOyryYSex",
        "outputId": "656f700f-240d-4c2c-f79b-f84c9e9ae495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model \n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same')) \n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model.add(Flatten()) \n",
        "model.add(Dropout(0.4)) \n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3))) \n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3))) \n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "UznOfF0iZOr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap4np_VbZcCA",
        "outputId": "51d85d08-1269-4d5a-c12a-4af978aaf013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               51300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,961,284\n",
            "Trainable params: 2,961,284\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tV3NnNyYZy6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model \n",
        "lrate = 0.01 \n",
        "epochs = 100\n",
        "decay = lrate/epochs \n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False) \n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMypzMWGZerT",
        "outputId": "eefe8bd7-cb25-4a99-d518-9d24b7f707d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs= epochs, batch_size = 32) \n",
        "# Final evaluation of the model \n",
        "scores = model.evaluate(X_test, y_test, verbose=0) \n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAJCVPTeZrHl",
        "outputId": "4d195124-5be8-4632-9e93-f5500b389735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.2251 - accuracy: 0.0514 - val_loss: 3.7519 - val_accuracy: 0.1188\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 3.5617 - accuracy: 0.1523 - val_loss: 3.2307 - val_accuracy: 0.2205\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 3.1049 - accuracy: 0.2384 - val_loss: 2.8823 - val_accuracy: 0.2866\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.7628 - accuracy: 0.3012 - val_loss: 2.6608 - val_accuracy: 0.3281\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 2.4999 - accuracy: 0.3574 - val_loss: 2.4832 - val_accuracy: 0.3688\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2724 - accuracy: 0.4043 - val_loss: 2.4002 - val_accuracy: 0.3883\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0627 - accuracy: 0.4486 - val_loss: 2.2714 - val_accuracy: 0.4135\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8812 - accuracy: 0.4886 - val_loss: 2.3149 - val_accuracy: 0.4139\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7217 - accuracy: 0.5258 - val_loss: 2.2731 - val_accuracy: 0.4253\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5608 - accuracy: 0.5625 - val_loss: 2.2294 - val_accuracy: 0.4386\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4049 - accuracy: 0.5984 - val_loss: 2.2776 - val_accuracy: 0.4390\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2618 - accuracy: 0.6335 - val_loss: 2.2876 - val_accuracy: 0.4481\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1377 - accuracy: 0.6632 - val_loss: 2.3836 - val_accuracy: 0.4417\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0102 - accuracy: 0.6987 - val_loss: 2.4079 - val_accuracy: 0.4471\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9114 - accuracy: 0.7246 - val_loss: 2.5479 - val_accuracy: 0.4436\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8119 - accuracy: 0.7509 - val_loss: 2.5885 - val_accuracy: 0.4436\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7322 - accuracy: 0.7737 - val_loss: 2.6449 - val_accuracy: 0.4370\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6510 - accuracy: 0.7973 - val_loss: 2.6618 - val_accuracy: 0.4497\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5853 - accuracy: 0.8165 - val_loss: 2.7404 - val_accuracy: 0.4529\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5288 - accuracy: 0.8309 - val_loss: 2.8537 - val_accuracy: 0.4542\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4762 - accuracy: 0.8469 - val_loss: 2.9707 - val_accuracy: 0.4537\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4396 - accuracy: 0.8609 - val_loss: 3.0064 - val_accuracy: 0.4558\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3991 - accuracy: 0.8729 - val_loss: 3.1641 - val_accuracy: 0.4488\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3529 - accuracy: 0.8872 - val_loss: 3.0985 - val_accuracy: 0.4543\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3260 - accuracy: 0.8963 - val_loss: 3.3253 - val_accuracy: 0.4512\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2960 - accuracy: 0.9045 - val_loss: 3.4374 - val_accuracy: 0.4501\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2820 - accuracy: 0.9108 - val_loss: 3.3606 - val_accuracy: 0.4536\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2606 - accuracy: 0.9158 - val_loss: 3.4962 - val_accuracy: 0.4633\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2369 - accuracy: 0.9247 - val_loss: 3.5090 - val_accuracy: 0.4524\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2167 - accuracy: 0.9306 - val_loss: 3.4566 - val_accuracy: 0.4620\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2037 - accuracy: 0.9346 - val_loss: 3.5486 - val_accuracy: 0.4535\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1885 - accuracy: 0.9398 - val_loss: 3.5993 - val_accuracy: 0.4623\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1760 - accuracy: 0.9427 - val_loss: 3.6924 - val_accuracy: 0.4589\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1653 - accuracy: 0.9461 - val_loss: 3.6969 - val_accuracy: 0.4625\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1603 - accuracy: 0.9481 - val_loss: 3.6869 - val_accuracy: 0.4581\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1514 - accuracy: 0.9508 - val_loss: 3.7758 - val_accuracy: 0.4600\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1394 - accuracy: 0.9542 - val_loss: 3.8889 - val_accuracy: 0.4593\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1303 - accuracy: 0.9571 - val_loss: 3.8205 - val_accuracy: 0.4621\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1230 - accuracy: 0.9608 - val_loss: 3.9482 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1116 - accuracy: 0.9637 - val_loss: 3.9651 - val_accuracy: 0.4616\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1129 - accuracy: 0.9630 - val_loss: 3.9417 - val_accuracy: 0.4632\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1093 - accuracy: 0.9641 - val_loss: 3.9385 - val_accuracy: 0.4652\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0971 - accuracy: 0.9687 - val_loss: 4.1279 - val_accuracy: 0.4666\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0967 - accuracy: 0.9690 - val_loss: 4.0010 - val_accuracy: 0.4673\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0917 - accuracy: 0.9703 - val_loss: 4.1050 - val_accuracy: 0.4657\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0911 - accuracy: 0.9707 - val_loss: 4.0244 - val_accuracy: 0.4655\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0875 - accuracy: 0.9715 - val_loss: 4.2622 - val_accuracy: 0.4677\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 4.1336 - val_accuracy: 0.4678\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0758 - accuracy: 0.9757 - val_loss: 4.2399 - val_accuracy: 0.4705\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0761 - accuracy: 0.9758 - val_loss: 4.1456 - val_accuracy: 0.4708\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0748 - accuracy: 0.9751 - val_loss: 4.2595 - val_accuracy: 0.4691\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0672 - accuracy: 0.9787 - val_loss: 4.2347 - val_accuracy: 0.4722\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0702 - accuracy: 0.9774 - val_loss: 4.1986 - val_accuracy: 0.4719\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0644 - accuracy: 0.9790 - val_loss: 4.3510 - val_accuracy: 0.4702\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 4.2727 - val_accuracy: 0.4751\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0593 - accuracy: 0.9813 - val_loss: 4.3104 - val_accuracy: 0.4745\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 4.3401 - val_accuracy: 0.4682\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0575 - accuracy: 0.9819 - val_loss: 4.2807 - val_accuracy: 0.4714\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 4.3798 - val_accuracy: 0.4730\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 4.3338 - val_accuracy: 0.4690\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0532 - accuracy: 0.9837 - val_loss: 4.3929 - val_accuracy: 0.4760\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 4.3799 - val_accuracy: 0.4727\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 4.3899 - val_accuracy: 0.4738\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0451 - accuracy: 0.9856 - val_loss: 4.4519 - val_accuracy: 0.4752\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 4.3843 - val_accuracy: 0.4713\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 4.4576 - val_accuracy: 0.4735\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0428 - accuracy: 0.9868 - val_loss: 4.4478 - val_accuracy: 0.4760\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 4.4857 - val_accuracy: 0.4744\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 4.4528 - val_accuracy: 0.4762\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0419 - accuracy: 0.9864 - val_loss: 4.4916 - val_accuracy: 0.4744\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 4.4863 - val_accuracy: 0.4745\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 4.4590 - val_accuracy: 0.4733\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 4.5223 - val_accuracy: 0.4724\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 4.5522 - val_accuracy: 0.4752\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 4.6114 - val_accuracy: 0.4763\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 4.6185 - val_accuracy: 0.4691\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 4.6076 - val_accuracy: 0.4724\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 4.5992 - val_accuracy: 0.4741\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 4.4959 - val_accuracy: 0.4752\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 4.5337 - val_accuracy: 0.4740\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 4.5935 - val_accuracy: 0.4747\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 4.5543 - val_accuracy: 0.4730\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 4.5923 - val_accuracy: 0.4728\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 4.6246 - val_accuracy: 0.4760\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 4.7857 - val_accuracy: 0.4762\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 4.6875 - val_accuracy: 0.4739\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 4.7145 - val_accuracy: 0.4749\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 4.7990 - val_accuracy: 0.4748\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 4.6631 - val_accuracy: 0.4770\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 4.6106 - val_accuracy: 0.4768\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 4.7868 - val_accuracy: 0.4783\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 4.7240 - val_accuracy: 0.4752\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 4.7991 - val_accuracy: 0.4738\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 4.8576 - val_accuracy: 0.4717\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 4.7200 - val_accuracy: 0.4773\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 4.7911 - val_accuracy: 0.4734\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 4.8373 - val_accuracy: 0.4758\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 4.7444 - val_accuracy: 0.4759\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 4.8045 - val_accuracy: 0.4796\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 4.7913 - val_accuracy: 0.4774\n",
            "Accuracy: 47.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis = 1) \n",
        "label = np.argmax(y_test,axis = 1)\n",
        "r = confusion_matrix(pred, label)\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lePglaCeZwdL",
        "outputId": "d5a1dba1-9005-4dce-f45f-3cb720c34c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[75  0  2 ...  0  0  0]\n",
            " [ 0 56  0 ...  0  0  0]\n",
            " [ 0  0 41 ...  0  7  1]\n",
            " ...\n",
            " [ 0  0  0 ... 48  0  0]\n",
            " [ 0  0  5 ...  0 22  1]\n",
            " [ 0  0  0 ...  0  1 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pythonistaplanet.com/cifar-10-image-classification-using-keras/"
      ],
      "metadata": {
        "id": "AiJKAgp_Zxxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19, ResNet50"
      ],
      "metadata": {
        "id": "koPxEuonaXtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "'Lastly import the final layers that will be added on top of the base model'\n",
        "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
        "\n",
        "'Import to_categorical from the keras utils package to one hot encode the labels'\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "MzjQ0bfga71Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the model\n",
        "\n",
        "'The first base model used is VGG19. The pretrained weights from the imagenet challenge are used'\n",
        "base_model_1 = VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])\n",
        "\n",
        "'For the 2nd base model we will use Resnet 50 and compare the performance against the previous one.The hypothesis is that Resnet 50 should perform better because of its deeper architecture'\n",
        "base_model_2 = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])"
      ],
      "metadata": {
        "id": "kdclZtdRac7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1= Sequential()\n",
        "model_1.add(base_model_1)\n",
        "model_1.add(Flatten())\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "#model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(y_train.shape[1],activation=('softmax'))) #This is the classification layer"
      ],
      "metadata": {
        "id": "ZtwCtCeuainD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check final model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR5v31qOaskK",
        "outputId": "65157bde-e91d-4993-eafb-0328adf4f69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,251,620\n",
            "Trainable params: 21,251,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "learn_rate= 0.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjr9DSS7axxj",
        "outputId": "1da595df-b18c-40cf-9c1f-2d60c50aa8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs= epochs, batch_size= batch_size) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--_MgOAVbElx",
        "outputId": "c9c07e0a-9963-4c48-83d9-de66a8adf201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 3.9866 - accuracy: 0.1079 - val_loss: 3.1466 - val_accuracy: 0.2408\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 2.7068 - accuracy: 0.3143 - val_loss: 2.4030 - val_accuracy: 0.3719\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 2.2258 - accuracy: 0.4051 - val_loss: 2.1277 - val_accuracy: 0.4331\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 1.9480 - accuracy: 0.4674 - val_loss: 1.9694 - val_accuracy: 0.4574\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 1.7470 - accuracy: 0.5138 - val_loss: 1.8681 - val_accuracy: 0.4866\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 30s 76ms/step - loss: 1.5939 - accuracy: 0.5494 - val_loss: 1.8244 - val_accuracy: 0.5008\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 1.4607 - accuracy: 0.5843 - val_loss: 1.8244 - val_accuracy: 0.5018\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 1.3402 - accuracy: 0.6143 - val_loss: 1.7303 - val_accuracy: 0.5324\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 1.2443 - accuracy: 0.6352 - val_loss: 1.7441 - val_accuracy: 0.5381\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 1.1361 - accuracy: 0.6650 - val_loss: 1.7487 - val_accuracy: 0.5329\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 1.0283 - accuracy: 0.6907 - val_loss: 1.7601 - val_accuracy: 0.5413\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.9337 - accuracy: 0.7166 - val_loss: 1.6932 - val_accuracy: 0.5581\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.8475 - accuracy: 0.7413 - val_loss: 1.7816 - val_accuracy: 0.5413\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.7626 - accuracy: 0.7623 - val_loss: 1.7374 - val_accuracy: 0.5555\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.6714 - accuracy: 0.7898 - val_loss: 1.8791 - val_accuracy: 0.5482\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.5807 - accuracy: 0.8152 - val_loss: 1.8681 - val_accuracy: 0.5664\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.5104 - accuracy: 0.8356 - val_loss: 2.0334 - val_accuracy: 0.5489\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.4478 - accuracy: 0.8546 - val_loss: 2.0513 - val_accuracy: 0.5669\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.3980 - accuracy: 0.8696 - val_loss: 2.1026 - val_accuracy: 0.5602\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.3425 - accuracy: 0.8884 - val_loss: 2.2520 - val_accuracy: 0.5655\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.3151 - accuracy: 0.8962 - val_loss: 2.4403 - val_accuracy: 0.5638\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.2528 - accuracy: 0.9169 - val_loss: 2.5038 - val_accuracy: 0.5598\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.2136 - accuracy: 0.9274 - val_loss: 2.6148 - val_accuracy: 0.5664\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.1880 - accuracy: 0.9370 - val_loss: 2.7603 - val_accuracy: 0.5652\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1791 - accuracy: 0.9404 - val_loss: 2.6770 - val_accuracy: 0.5632\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1650 - accuracy: 0.9450 - val_loss: 2.5708 - val_accuracy: 0.5521\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1439 - accuracy: 0.9521 - val_loss: 2.8483 - val_accuracy: 0.5621\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1101 - accuracy: 0.9641 - val_loss: 2.7248 - val_accuracy: 0.5687\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1014 - accuracy: 0.9670 - val_loss: 2.9415 - val_accuracy: 0.5682\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1062 - accuracy: 0.9654 - val_loss: 2.8937 - val_accuracy: 0.5641\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0892 - accuracy: 0.9707 - val_loss: 2.9359 - val_accuracy: 0.5599\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0737 - accuracy: 0.9761 - val_loss: 2.8267 - val_accuracy: 0.5623\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 3.2996 - val_accuracy: 0.5676\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0674 - accuracy: 0.9789 - val_loss: 3.3074 - val_accuracy: 0.5584\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 3.4093 - val_accuracy: 0.5696\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 3.1208 - val_accuracy: 0.5689\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 3.5727 - val_accuracy: 0.5698\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 3.4349 - val_accuracy: 0.5825\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 3.4242 - val_accuracy: 0.5600\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 3.3046 - val_accuracy: 0.5657\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 3.3745 - val_accuracy: 0.5631\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0416 - accuracy: 0.9864 - val_loss: 3.2485 - val_accuracy: 0.5734\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 3.5136 - val_accuracy: 0.5802\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 3.6248 - val_accuracy: 0.5769\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 3.4975 - val_accuracy: 0.5678\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 3.8302 - val_accuracy: 0.5716\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 3.5978 - val_accuracy: 0.5853\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 3.6517 - val_accuracy: 0.5783\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 3.8913 - val_accuracy: 0.5800\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 3.7799 - val_accuracy: 0.5793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d43c95910>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model \n",
        "scores = model_1.evaluate(X_test, y_test, verbose=0) \n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1abJTSTdTHdU",
        "outputId": "e1b1ae0f-9e6f-463d-9f2d-67a04d97b53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 57.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1= Sequential()\n",
        "model_1.add(base_model_2)\n",
        "model_1.add(Flatten())\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "#model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(y_train.shape[1],activation=('softmax'))) #This is the classification layer\\\n",
        "\n",
        "#Check final model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIw7zaMCTRS3",
        "outputId": "c221b696-f6b2-456c-941f-120436ccdb98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,387,812\n",
            "Trainable params: 26,334,692\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "learn_rate= 0.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6fGiGWTTaye",
        "outputId": "237ae4a7-59b2-4cf9-bced-f53f9727c06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs= epochs, batch_size= batch_size) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm7JXuGWTe6h",
        "outputId": "4f8d2f0f-fd6c-4c59-9678-175557af5436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 30s 66ms/step - loss: 4.4450 - accuracy: 0.0517 - val_loss: 7.5293 - val_accuracy: 0.0102\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 3.5505 - accuracy: 0.2070 - val_loss: 4.3450 - val_accuracy: 0.0942\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 26s 68ms/step - loss: 2.6210 - accuracy: 0.3537 - val_loss: 2.6418 - val_accuracy: 0.3468\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 2.0231 - accuracy: 0.4700 - val_loss: 2.3763 - val_accuracy: 0.4011\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.6105 - accuracy: 0.5630 - val_loss: 2.2380 - val_accuracy: 0.4353\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.2900 - accuracy: 0.6390 - val_loss: 2.2319 - val_accuracy: 0.4518\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.0170 - accuracy: 0.7104 - val_loss: 2.4100 - val_accuracy: 0.4431\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.8233 - accuracy: 0.7615 - val_loss: 2.3844 - val_accuracy: 0.4632\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.6403 - accuracy: 0.8098 - val_loss: 2.5907 - val_accuracy: 0.4517\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.5054 - accuracy: 0.8494 - val_loss: 2.5861 - val_accuracy: 0.4611\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.3933 - accuracy: 0.8821 - val_loss: 2.6933 - val_accuracy: 0.4762\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.3147 - accuracy: 0.9059 - val_loss: 2.8711 - val_accuracy: 0.4645\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.2519 - accuracy: 0.9229 - val_loss: 3.0058 - val_accuracy: 0.4706\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.2022 - accuracy: 0.9387 - val_loss: 2.9841 - val_accuracy: 0.4830\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.1753 - accuracy: 0.9464 - val_loss: 3.1443 - val_accuracy: 0.4732\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.1515 - accuracy: 0.9545 - val_loss: 3.1272 - val_accuracy: 0.4836\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.1278 - accuracy: 0.9621 - val_loss: 3.1952 - val_accuracy: 0.4870\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.1073 - accuracy: 0.9679 - val_loss: 3.2923 - val_accuracy: 0.4853\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.1044 - accuracy: 0.9677 - val_loss: 3.3419 - val_accuracy: 0.4825\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.0968 - accuracy: 0.9701 - val_loss: 3.5598 - val_accuracy: 0.4727\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.0804 - accuracy: 0.9760 - val_loss: 3.4387 - val_accuracy: 0.4868\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.0777 - accuracy: 0.9775 - val_loss: 3.4672 - val_accuracy: 0.4844\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.0756 - accuracy: 0.9774 - val_loss: 3.5015 - val_accuracy: 0.4853\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.0718 - accuracy: 0.9778 - val_loss: 3.5338 - val_accuracy: 0.4865\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.0644 - accuracy: 0.9809 - val_loss: 3.5511 - val_accuracy: 0.4848\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 3.5344 - val_accuracy: 0.4963\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 3.6628 - val_accuracy: 0.4922\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 3.6031 - val_accuracy: 0.4940\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0510 - accuracy: 0.9846 - val_loss: 3.6138 - val_accuracy: 0.4958\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 3.6946 - val_accuracy: 0.4948\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 3.7276 - val_accuracy: 0.4917\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 3.7591 - val_accuracy: 0.4886\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 3.9147 - val_accuracy: 0.4781\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 3.7092 - val_accuracy: 0.5049\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 3.7796 - val_accuracy: 0.4945\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 3.7122 - val_accuracy: 0.5006\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0343 - accuracy: 0.9897 - val_loss: 3.6997 - val_accuracy: 0.5013\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 3.6853 - val_accuracy: 0.5083\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 3.7372 - val_accuracy: 0.5097\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 3.7944 - val_accuracy: 0.5067\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 3.8336 - val_accuracy: 0.4990\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 3.7411 - val_accuracy: 0.5063\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 3.7637 - val_accuracy: 0.5085\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 3.8127 - val_accuracy: 0.5105\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 3.8626 - val_accuracy: 0.5074\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 3.8983 - val_accuracy: 0.5060\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 3.8322 - val_accuracy: 0.5115\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 3.9560 - val_accuracy: 0.5062\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 3.8723 - val_accuracy: 0.5094\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 3.9133 - val_accuracy: 0.5081\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9c3f92fe10>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model \n",
        "scores = model_1.evaluate(X_test, y_test, verbose=0) \n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ViYWgiTfqL",
        "outputId": "f4f82308-2ecb-4dee-fd92-a65e5a37e9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = model_1.predict(X_test)\n",
        "pred = np.argmax(pred, axis = 1) \n",
        "label = np.argmax(y_test,axis = 1)\n",
        "r = confusion_matrix(pred, label)\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sATkc4WbYtvT",
        "outputId": "dbeba446-99aa-4932-e44c-821ac5be73c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[850  13  48  15  16  14   4  13  41  19]\n",
            " [ 15 865   5   9   3   5   2   4  26  62]\n",
            " [ 21   5 719  62  51  43  48  17   8   6]\n",
            " [ 14   1  42 600  40 143  36  32   6   8]\n",
            " [  9   2  81  62 778  50  24  35   9   4]\n",
            " [  1   8  27 118  22 655  18  28   2   7]\n",
            " [  7   4  48  60  34  24 855   6   1   3]\n",
            " [ 10   2  16  37  42  53   8 846   1   8]\n",
            " [ 54  29  10  19  11   9   4   6 896  27]\n",
            " [ 19  71   4  18   3   4   1  13  10 856]]\n"
          ]
        }
      ]
    }
  ]
}